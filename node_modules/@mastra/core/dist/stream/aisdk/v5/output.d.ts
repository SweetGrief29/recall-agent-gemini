import type { ReadableStream } from 'stream/web';
import type { TextStreamPart, ToolSet, UIMessage, UIMessageStreamOptions } from 'ai-v5';
import type z from 'zod';
import type { MessageList } from '../../../agent/message-list/index.js';
import type { MastraModelOutput } from '../../base/output.js';
import type { OutputSchema } from '../../base/schema.js';
import type { ConsumeStreamOptions } from './compat/index.js';
import type { OutputChunkType } from './transform.js';
type AISDKV5OutputStreamOptions<OUTPUT extends OutputSchema = undefined> = {
    toolCallStreaming?: boolean;
    includeRawChunks?: boolean;
    output?: OUTPUT;
};
export type AIV5FullStreamPart<T = undefined> = T extends undefined ? TextStreamPart<ToolSet> : TextStreamPart<ToolSet> | {
    type: 'object';
    object: T extends z.ZodSchema ? Partial<z.infer<T>> : unknown;
};
export type AIV5FullStreamType<T> = ReadableStream<AIV5FullStreamPart<T>>;
export declare class AISDKV5OutputStream<OUTPUT extends OutputSchema = undefined> {
    #private;
    constructor({ modelOutput, options, messageList, }: {
        modelOutput: MastraModelOutput<OUTPUT>;
        options: AISDKV5OutputStreamOptions<OUTPUT>;
        messageList: MessageList;
    });
    toTextStreamResponse(init?: ResponseInit): Response;
    toUIMessageStreamResponse<UI_MESSAGE extends UIMessage>({ generateMessageId, originalMessages, sendFinish, sendReasoning, sendSources, onError, sendStart, messageMetadata, onFinish, ...init }?: UIMessageStreamOptions<UI_MESSAGE> & ResponseInit): Response;
    toUIMessageStream<UI_MESSAGE extends UIMessage>({ generateMessageId, originalMessages, sendFinish, sendReasoning, sendSources, onError, sendStart, messageMetadata, onFinish, }?: UIMessageStreamOptions<UI_MESSAGE>): globalThis.ReadableStream<import("ai-v5").InferUIMessageChunk<UI_MESSAGE>>;
    consumeStream(options?: ConsumeStreamOptions): Promise<void>;
    get sources(): Promise<OutputChunkType[]>;
    get files(): Promise<any[]>;
    get text(): Promise<string>;
    /**
     * Stream of valid JSON chunks. The final JSON result is validated against the output schema when the stream ends.
     */
    get objectStream(): ReadableStream<import("../../base/schema").PartialSchemaOutput<OUTPUT>>;
    get generateTextFiles(): Promise<any[]>;
    get toolCalls(): Promise<OutputChunkType[]>;
    get toolResults(): Promise<OutputChunkType[]>;
    get reasoningText(): Promise<string | undefined>;
    get reasoning(): Promise<{
        type: string;
        text: string;
        providerMetadata: import("@ai-sdk/provider-v5").SharedV2ProviderMetadata;
    }[]>;
    get response(): Promise<{
        [x: string]: any;
    }>;
    get steps(): Promise<import("./output-helpers").DefaultStepResult<any>[]>;
    get generateTextSteps(): Promise<import("./output-helpers").DefaultStepResult<any>[]>;
    get content(): ({
        type: "text";
        text: string;
        providerMetadata?: import("ai-v5").ProviderMetadata;
    } | {
        type: "reasoning";
        text: string;
        providerMetadata?: import("ai-v5").ProviderMetadata;
    } | ({
        type: "source";
    } & import("@ai-sdk/provider-v5").LanguageModelV2Source) | {
        type: "file";
        file: import("ai-v5").Experimental_GeneratedImage;
        providerMetadata?: import("ai-v5").ProviderMetadata;
    } | ({
        type: "tool-call";
    } & (import("ai-v5").TypedToolCall<any> & {
        providerMetadata?: import("ai-v5").ProviderMetadata;
    })) | ({
        type: "tool-result";
    } & (import("ai-v5").TypedToolResult<any> & {
        providerMetadata?: import("ai-v5").ProviderMetadata;
    })) | ({
        type: "tool-error";
    } & (import("ai-v5").TypedToolError<any> & {
        providerMetadata?: import("ai-v5").ProviderMetadata;
    })))[];
    /**
     * Stream of only text content, compatible with streaming text responses.
     */
    get textStream(): ReadableStream<string>;
    /**
     * Stream of individual array elements when output schema is an array type.
     */
    get elementStream(): ReadableStream<import("../../base/schema").InferSchemaOutput<OUTPUT> extends (infer T)[] ? T : never>;
    /**
     * Stream of all chunks in AI SDK v5 format.
     */
    get fullStream(): AIV5FullStreamType<OUTPUT>;
    getFullOutput(): Promise<{
        object?: NonNullable<Awaited<import("../../base/schema").InferSchemaOutput<OUTPUT>>> | undefined;
        text: string;
        usage: Record<string, number>;
        steps: import("./output-helpers").DefaultStepResult<any>[];
        finishReason: string | undefined;
        warnings: import("@ai-sdk/provider-v5").LanguageModelV2CallWarning[];
        providerMetadata: Record<string, any> | undefined;
        request: Record<string, any>;
        reasoning: {
            type: string;
            text: string;
            providerMetadata: import("@ai-sdk/provider-v5").SharedV2ProviderMetadata;
        }[];
        reasoningText: string | undefined;
        toolCalls: OutputChunkType[];
        toolResults: OutputChunkType[];
        sources: OutputChunkType[];
        files: any[];
        response: {
            [x: string]: any;
        };
        content: ({
            type: "text";
            text: string;
            providerMetadata?: import("ai-v5").ProviderMetadata;
        } | {
            type: "reasoning";
            text: string;
            providerMetadata?: import("ai-v5").ProviderMetadata;
        } | ({
            type: "source";
        } & import("@ai-sdk/provider-v5").LanguageModelV2Source) | {
            type: "file";
            file: import("ai-v5").Experimental_GeneratedImage;
            providerMetadata?: import("ai-v5").ProviderMetadata;
        } | ({
            type: "tool-call";
        } & (import("ai-v5").TypedToolCall<any> & {
            providerMetadata?: import("ai-v5").ProviderMetadata;
        })) | ({
            type: "tool-result";
        } & (import("ai-v5").TypedToolResult<any> & {
            providerMetadata?: import("ai-v5").ProviderMetadata;
        })) | ({
            type: "tool-error";
        } & (import("ai-v5").TypedToolError<any> & {
            providerMetadata?: import("ai-v5").ProviderMetadata;
        })))[];
        totalUsage: Record<string, number>;
        error: string | Error | {
            message: string;
            stack: string;
        } | undefined;
        tripwire: boolean;
        tripwireReason: string;
    }>;
    get tripwire(): boolean;
    get tripwireReason(): string;
    get error(): string | Error | {
        message: string;
        stack: string;
    } | undefined;
    get object(): Promise<import("../../base/schema").InferSchemaOutput<OUTPUT>>;
}
export {};
//# sourceMappingURL=output.d.ts.map